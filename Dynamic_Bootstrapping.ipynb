{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Bootstrapping\n",
    "\n",
    "This notebook outlines some of my initial thoughts on using bootstrap samples of decreasing balance to learn models on highly imbalanced datasets.  The idea is to start training a model with bootstrap samples of balanced classes and gradually decay the balance to the true distribution as learning takes place much like the learning rate.  The hope is that this will allow the classifier to identify patterns related to the minority class and then gradually come to recognize the true distribution.  Hopefully it becomes less biased towards the minority as time goes on and the bootstrap samples approach the true distribution.\n",
    "\n",
    "### Data\n",
    "\n",
    "All data was taken from the https://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction/data challenge.  Just unzip the Train.zip file into the directory with this notebook in order to run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM\n",
    "from keras.optimizers import SGD, Adam\n",
    "import warnings\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, precision_recall_curve,average_precision_score\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>How to check if an uploaded file is an image w...</td>\n",
       "      <td>&lt;p&gt;I'd like to check if an uploaded file is an...</td>\n",
       "      <td>php image-processing file-upload upload mime-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>How can I prevent firefox from closing when I ...</td>\n",
       "      <td>&lt;p&gt;In my favorite editor (vim), I regularly us...</td>\n",
       "      <td>firefox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>R Error Invalid type (list) for variable</td>\n",
       "      <td>&lt;p&gt;I am import matlab file and construct a dat...</td>\n",
       "      <td>r matlab machine-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>How do I replace special characters in a URL?</td>\n",
       "      <td>&lt;p&gt;This is probably very simple, but I simply ...</td>\n",
       "      <td>c# url encoding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>How to modify whois contact details?</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;function modify(.......)\\n{\\n  $mco...</td>\n",
       "      <td>php api file-get-contents</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                              Title  \\\n",
       "0   1  How to check if an uploaded file is an image w...   \n",
       "1   2  How can I prevent firefox from closing when I ...   \n",
       "2   3           R Error Invalid type (list) for variable   \n",
       "3   4      How do I replace special characters in a URL?   \n",
       "4   5               How to modify whois contact details?   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I'd like to check if an uploaded file is an...   \n",
       "1  <p>In my favorite editor (vim), I regularly us...   \n",
       "2  <p>I am import matlab file and construct a dat...   \n",
       "3  <p>This is probably very simple, but I simply ...   \n",
       "4  <pre><code>function modify(.......)\\n{\\n  $mco...   \n",
       "\n",
       "                                                Tags  \n",
       "0  php image-processing file-upload upload mime-t...  \n",
       "1                                            firefox  \n",
       "2                          r matlab machine-learning  \n",
       "3                                    c# url encoding  \n",
       "4                          php api file-get-contents  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the data\n",
    "data = pd.read_csv('Train.csv', nrows=250000)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "max_length = 350  # length of input sequences to the model\n",
    "n_top_tags = 1  # n most prevelant tags to try to predict\n",
    "vocab_size = 2000  # How many distinct tokens to take\n",
    "char_model = False  # type of model to train (character or word)\n",
    "batch_size = 128\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['php image-processing file-upload upload mime-types', 'firefox', 'r matlab machine-learning', 'c# url encoding', 'php api file-get-contents', 'proxy active-directory jmeter', 'core-plot', 'c# asp.net windows-phone-7', '.net javascript code-generation', 'sql variables parameters procedure calls', '.net obfuscation reflector', 'algorithm language-agnostic random', 'postfix migration mdaemon', 'documentation latex3 expl3', 'windows-7', 'php url-routing conventions', 'r temporary-files', 'wpf binding', 'javascript code-generation playframework minify', 'php xml hash multidimensional-array simplexml-load-string', 'medical-science cancer healthcare', 'c# .net linq', 'actionscript-3 flex flex3', 'iis', 'c# linq string enumeration']\n",
      "===================================================================================================================\n",
      "[\"<p>I'd like to check if an uploaded file is an image file (e.g png, jpg, jpeg, gif, bmp) or another file. The problem is that I'm using Uploadify to upload the files, which changes the mime type and gives a 'text/octal' or something as the mime type, no matter which file type you upload.</p>\\n\\n<p>Is there a way to check if the uploaded file is an image apart from checking the file extension using PHP?</p>\\n\", '<p>In my favorite editor (vim), I regularly use ctrl-w to execute a certain action. Now, it quite often happens to me that firefox is the active window (on windows) while I still look at vim (thinking vim is the active window) and press ctrl-w which closes firefox. This is not what I want. Is there a way to stop ctrl-w from closing firefox?</p>\\n\\n<p>Rene</p>\\n']\n"
     ]
    }
   ],
   "source": [
    "# Convert the tags and texts to lists for the keras tokenizer\n",
    "tag_list = data['Tags'].tolist()\n",
    "text_list = data['Body'].tolist()\n",
    "\n",
    "print(tag_list[:25])\n",
    "print(\"=\"*115)\n",
    "print(text_list[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the labels\n",
    "tag = 'c#'\n",
    "tag_matrix = np.array([[(tag in x.split(' ')) + 0.0] for x in tag_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_tokenizer = Tokenizer(num_words=n_top_tags + 1)\n",
    "# tag_tokenizer.fit_on_texts(tag_list)\n",
    "# tag_matrix = tag_tokenizer.texts_to_matrix(tag_list)[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 1)\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(tag_matrix.shape)\n",
    "print(tag_matrix)\n",
    "# print(list(tag_tokenizer.word_index.keys())[:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "[[1, 381, 51, 4, 335, 23, 34, 1868, 53, 9, 34, 142, 53, 92, 274, 334, 548, 1658, 44, 261, 53, 2, 99, 9, 16, 52, 45, 4, 795, 2, 166, 61, 607, 2, 79, 10, 798, 6, 44, 153, 28, 2, 79, 100, 1417, 61, 53, 79, 81, 795, 1, 1, 9, 56, 6, 86, 4, 335, 23, 2, 1868, 53, 9, 34, 142, 32, 1278, 2, 53, 1024, 45, 102, 1], [1, 12, 21, 1171, 3, 67, 536, 4, 583, 6, 844, 307, 136, 15, 903, 1694, 893, 4, 84, 16, 954, 9, 2, 746, 338, 22, 178, 240, 3, 311, 512, 43, 1028, 9, 2, 746, 338, 10, 1384, 536, 61, 954, 13, 9, 27, 59, 3, 62, 9, 56, 6, 86, 4, 774, 536, 32, 954, 1, 1, 1]]\n",
      "['p', 'the', 'i', 'to', 'code', 'a', 'gt', 'lt', 'is', 'and', 'pre', 'in', 'this', 'of', 'it', 'that', 'for', '0', '1', 'have', 'my', 'on', 'if', 'with', 'but']\n",
      "['directories', 'fragment', 'argv', 'nginx', 'uiimage', 'updating', 'identifier', 'v1', 'uk', 'relationship', 'annotation', 'eg', 'embedded', 'htaccess', \"name'\", 'conditions', 'putting', '0000', 'mysite', 'inf', 'fairly', 'went', 'emails', \"'s\", 'escape']\n"
     ]
    }
   ],
   "source": [
    "text_tokenizer = Tokenizer(num_words=vocab_size, char_level=char_model)\n",
    "text_tokenizer.fit_on_texts(text_list)\n",
    "text_matrix = text_tokenizer.texts_to_sequences(text_list)\n",
    "\n",
    "# We have a numeric representation of the words in the questions\n",
    "print(vocab_size)\n",
    "print(text_matrix[:2])\n",
    "print(list(text_tokenizer.word_index.keys())[:25])\n",
    "print(list(text_tokenizer.word_index.keys())[vocab_size-25:vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padd all sequences to the same size\n",
    "X = sequence.pad_sequences(text_matrix, maxlen=max_length, padding='pre', truncating='post')\n",
    "\n",
    "y = tag_matrix\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a sequence model instead\n",
    "seq_model = Sequential()\n",
    "seq_model.add(Embedding(vocab_size, 100, input_shape=(max_length, )))\n",
    "seq_model.add(Dropout(.2))\n",
    "seq_model.add(LSTM(64))\n",
    "seq_model.add(Dropout(.2))\n",
    "seq_model.add(Dense(n_top_tags, activation='sigmoid'))\n",
    "seq_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 350, 100)          200000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 350, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 242,305\n",
      "Trainable params: 242,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "112320/200000 [===============>..............] - ETA: 12:37 - loss: 0.2382 - acc: 0.9209"
     ]
    }
   ],
   "source": [
    "for e in range(0, 10):\n",
    "    seq_model.fit(x_train, y_train, epochs=1)\n",
    "    predictions = seq_model.predict(x_val)\n",
    "    f1_scores = f1_score(y_val, predictions  > 0.5)\n",
    "    precision_scores = precision_score(y_val, predictions  > 0.5)\n",
    "    recall_scores = recall_score(y_val, predictions  > 0.5)\n",
    "    auc_scores = roc_auc_score(y_val, predictions)\n",
    "    avg_precision_score = average_precision_score(y_val, predictions)\n",
    "    normal_scores.append([e, f1_scores, precision_scores, recall_scores, auc_scores, avg_precision_score])\n",
    "    print(f1_scores, precision_scores, recall_scores, auc_scores, avg_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = seq_model.predict(x_val)\n",
    "f1_scores = f1_score(y_val, predictions  > 0.5)\n",
    "precision_scores = precision_score(y_val, predictions  > 0.5)\n",
    "recall_scores = recall_score(y_val, predictions  > 0.5)\n",
    "auc_scores = roc_auc_score(y_val, predictions)\n",
    "average_precision_score(y_val, predictions)\n",
    "print(f1_scores, precision_scores, recall_scores, auc_scores, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_score(y_val, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_scores.append([e, f1_scores, precision_scores, recall_scores, auc_scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Dynamic Bootstrapping \n",
    "\n",
    "Previously we just trained a model out of the box on the data.  Pefromance is fairly poor and most of the classes are just set to 0.  Here we use dynamic bootstrapping to initialize our model parameters and then train for a few epochs on the true dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a sequence model instead\n",
    "seq_model_boot = Sequential()\n",
    "seq_model_boot.add(Embedding(vocab_size, 100, input_shape=(max_length, )))\n",
    "seq_model_boot.add(Dropout(.2))\n",
    "seq_model_boot.add(LSTM(64))\n",
    "seq_model_boot.add(Dropout(.2))\n",
    "seq_model_boot.add(Dense(n_top_tags, activation='sigmoid'))\n",
    "seq_model_boot.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the true ratio of the training set.  This is the lower bound on how imblanaced the classes\n",
    "# are allowed to be\n",
    "true_ratio = np.sum(y_train) / y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So 313 bootstrap samples per epoch\n",
    "# Each bootstrap sample has 512 examples in it\n",
    "# We will use a batch size of 128\n",
    "\n",
    "# true_ratio = imbalance_ratio * x ^ (steps_per_epoch  * num_epochs)\n",
    "# true_ratio / imbalance_ratio = x ^ (steps_per_epoch  * num_epochs)\n",
    "# log(true_ratio) - log(imbalance_ratio) = steps_per_epoch  *num_epochs log(x)\n",
    "# log(true_ratio) - log(imbalance_ratio) / (steps_per_epoch * num_epochs) = log(x)\n",
    "# 10 ^ (log(true_ratio) - log(imbalance_ratio) / (steps_per_epoch * num_epochs)) = x\n",
    "\n",
    "def calculate_ratio_constant(num_data, batch_size, num_batches, num_epochs, true_ratio, imbalance_ratio):\n",
    "    \"\"\"Calculates the decay constant for the imbalance ratio\"\"\"\n",
    "    steps_per_epoch = num_data / (batch_size * num_batches)\n",
    "    return np.exp((np.log(true_ratio) - np.log(imbalance_ratio)) / (steps_per_epoch * num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 7\n",
    "num_batches_in_bootstrap_sample = 10\n",
    "imbalance_ratio = .5\n",
    "num_times_to_train_on_full_dataset = 3\n",
    "decay_rate = calculate_ratio_constant(y.shape[0], batch_size, num_batches_in_bootstrap_sample, num_epochs, true_ratio, imbalance_ratio)\n",
    "print(decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas dataframe of the x_train data to bootstrap sample\n",
    "x_train_df = pd.DataFrame(x_train)\n",
    "x_train_df['label'] = pd.Series(y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the positive and negative examples\n",
    "x_train_pos_df = x_train_df[x_train_df['label'] == 1.0]\n",
    "x_train_neg_df = x_train_df[x_train_df['label'] == 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap sample from the training set\n",
    "\n",
    "# start balanced\n",
    "sample_ration = .5\n",
    "\n",
    "validation_performance = []\n",
    "\n",
    "# Perform 4 epochs of training using bootstrap samples where the imbalance rate gradually approaches the true\n",
    "# distribution\n",
    "for i in range(0, num_epochs):\n",
    "    for j in range(0, int(y_train.shape[0] / (num_batches_in_bootstrap_sample * batch_size))):\n",
    "        pos_samples = (x_train_pos_df\n",
    "                       .sample(int(num_batches_in_bootstrap_sample * batch_size * imbalance_ratio), replace=True)\n",
    "                       .drop(columns='label')\n",
    "                       .as_matrix())\n",
    "        neg_samples = (x_train_neg_df\n",
    "                       .sample(int(num_batches_in_bootstrap_sample * batch_size * imbalance_ratio), replace=True)\n",
    "                       .drop(columns='label')\n",
    "                       .as_matrix())\n",
    "        x_train_sampled = np.concatenate([pos_samples, neg_samples])\n",
    "        y_train_pos = np.ones([pos_samples.shape[0], ])\n",
    "        y_train_neg = np.zeros([neg_samples.shape[0], ])\n",
    "        y_train_sampled = np.concatenate([y_train_pos, y_train_neg])\n",
    "        seq_model_boot.fit(x_train_sampled, y_train_sampled, epochs=1, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Update sample ratio\n",
    "        imbalance_ratio = imbalance_ratio * decay_rate\n",
    "    \n",
    "    # Every epoch print and save the validation performance\n",
    "    predictions = seq_model_boot.predict(x_val)\n",
    "    f1_scores = f1_score(y_val, predictions  > 0.5)\n",
    "    precision_scores = precision_score(y_val, predictions  > 0.5)\n",
    "    recall_scores = recall_score(y_val, predictions  > 0.5)\n",
    "    auc_scores = roc_auc_score(y_val, predictions)\n",
    "    avg_precision_score = average_precision_score(y_val, predictions)\n",
    "    validation_performance.append([f1_scores, precision_scores, recall_scores, auc_scores, avg_precision_score])\n",
    "    print(f1_scores, precision_scores, recall_scores, auc_scores, avg_precision_score)\n",
    "\n",
    "seq_model_boot.fit(x_train, y_train, epochs=num_times_to_train_on_full_dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model_boot.fit(x_train, y_train, epochs=num_times_to_train_on_full_dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = seq_model_boot.predict(x_val)\n",
    "f1_scores = f1_score(y_val, predictions  > 0.5)\n",
    "precision_scores = precision_score(y_val, predictions  > 0.5)\n",
    "recall_scores = recall_score(y_val, predictions  > 0.5)\n",
    "auc_scores = roc_auc_score(y_val, predictions)\n",
    "print(f1_scores, precision_scores, recall_scores, auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "\n",
    "```\n",
    "After 5 epochs trained on full data set we get:\n",
    "0.5976387002403092\n",
    "0.7844212835984641\n",
    "0.48270042194092827\n",
    "\n",
    "After 7\n",
    "0.6183401154537712 0.7037914691943128 0.5513924050632911\n",
    "\n",
    "After dynamic bootstrapping we get\n",
    "0.6410598233627728\n",
    "0.6330426197136745\n",
    "0.6492827004219409\n",
    "```\n",
    "\n",
    "It appears that dynamic bootstrapping gives, better performance.  It also appears that it converges more quickly to the optimum value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Sensitive Learning\n",
    "\n",
    "Use class weighting and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over Sampleing\n",
    "Here we just oversample the minority class to equal the majority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under Sampling\n",
    "\n",
    "Here we understample the majority class to equal the minority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE\n",
    "\n",
    "Use smote to create ideal dataset then run training for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
